---
layout: archive
title: "Session 5: The politics of big data"
permalink: /workshops/2019_session5
author_profile: true
---
*(Reflections from Stefanie Habersang)*  
  
In the panel session “The politics of big data” Chris Steele discussed with Wendy Espeland, David Krisch, Dev Jennings, and Joel Gehman truth(s) and fact(s) in the context of big data. Chris Steele started with an interesting introduction on the question “How are facts made?” using practice-driven institutionalism to introduce an ecology of fact-making. For the study of data per se he concludes that revealing the political ecology of facticity within which data is made and within which its consequences arise become fundamentally important in our field.

The main take-away from this panel discussion was that big data can easily give the impression that we overestimate what we can know – simply due to the sheer amount of data that is available. However, all data (big and small) may reveal some things and exclude other things. Therefore, the panel calls for a strong emphasis on reflexivity in collecting, analyzing, and interpreting big data. It is essential that we critically examine what we see and what we do not see/exclude in the data. It is our responsibility as scholars to understand the “taken-for-granted” assumptions that underpin our data (collection) and shape our interpretation. One way to reflect upon our own taken-for granted assumptions is constantly asking: What must be true for the data that we collect? It is important to think about the potential biases that we build into the data, not only during data collection but also by using the wrong methods.
